{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bfe8fe0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2538e15",
   "metadata": {},
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "936ed026",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = datasets.load_digits()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33c37a7",
   "metadata": {},
   "source": [
    "# keys del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "29a2514d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names'])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f87544",
   "metadata": {},
   "source": [
    "# Visualización del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "aa8d7949",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(data= df['data'],\n",
    "                    columns= df['feature_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "71a185e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14.20</td>\n",
       "      <td>1.76</td>\n",
       "      <td>2.45</td>\n",
       "      <td>15.2</td>\n",
       "      <td>112.0</td>\n",
       "      <td>3.27</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.97</td>\n",
       "      <td>6.75</td>\n",
       "      <td>1.05</td>\n",
       "      <td>2.85</td>\n",
       "      <td>1450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14.39</td>\n",
       "      <td>1.87</td>\n",
       "      <td>2.45</td>\n",
       "      <td>14.6</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.52</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.98</td>\n",
       "      <td>5.25</td>\n",
       "      <td>1.02</td>\n",
       "      <td>3.58</td>\n",
       "      <td>1290.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14.06</td>\n",
       "      <td>2.15</td>\n",
       "      <td>2.61</td>\n",
       "      <td>17.6</td>\n",
       "      <td>121.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.51</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.25</td>\n",
       "      <td>5.05</td>\n",
       "      <td>1.06</td>\n",
       "      <td>3.58</td>\n",
       "      <td>1295.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14.83</td>\n",
       "      <td>1.64</td>\n",
       "      <td>2.17</td>\n",
       "      <td>14.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.98</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.98</td>\n",
       "      <td>5.20</td>\n",
       "      <td>1.08</td>\n",
       "      <td>2.85</td>\n",
       "      <td>1045.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13.86</td>\n",
       "      <td>1.35</td>\n",
       "      <td>2.27</td>\n",
       "      <td>16.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>2.98</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.85</td>\n",
       "      <td>7.22</td>\n",
       "      <td>1.01</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1045.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "5    14.20        1.76  2.45               15.2      112.0           3.27   \n",
       "6    14.39        1.87  2.45               14.6       96.0           2.50   \n",
       "7    14.06        2.15  2.61               17.6      121.0           2.60   \n",
       "8    14.83        1.64  2.17               14.0       97.0           2.80   \n",
       "9    13.86        1.35  2.27               16.0       98.0           2.98   \n",
       "\n",
       "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "5        3.39                  0.34             1.97             6.75  1.05   \n",
       "6        2.52                  0.30             1.98             5.25  1.02   \n",
       "7        2.51                  0.31             1.25             5.05  1.06   \n",
       "8        2.98                  0.29             1.98             5.20  1.08   \n",
       "9        3.15                  0.22             1.85             7.22  1.01   \n",
       "\n",
       "   od280/od315_of_diluted_wines  proline  \n",
       "0                          3.92   1065.0  \n",
       "1                          3.40   1050.0  \n",
       "2                          3.17   1185.0  \n",
       "3                          3.45   1480.0  \n",
       "4                          2.93    735.0  \n",
       "5                          2.85   1450.0  \n",
       "6                          3.58   1290.0  \n",
       "7                          3.58   1295.0  \n",
       "8                          2.85   1045.0  \n",
       "9                          3.55   1045.0  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c78744f",
   "metadata": {},
   "source": [
    "## Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "be0148ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description:\n",
      " .. _wine_dataset:\n",
      "\n",
      "Wine recognition dataset\n",
      "------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 178 (50 in each of three classes)\n",
      "    :Number of Attributes: 13 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      " \t\t- Alcohol\n",
      " \t\t- Malic acid\n",
      " \t\t- Ash\n",
      "\t\t- Alcalinity of ash  \n",
      " \t\t- Magnesium\n",
      "\t\t- Total phenols\n",
      " \t\t- Flavanoids\n",
      " \t\t- Nonflavanoid phenols\n",
      " \t\t- Proanthocyanins\n",
      "\t\t- Color intensity\n",
      " \t\t- Hue\n",
      " \t\t- OD280/OD315 of diluted wines\n",
      " \t\t- Proline\n",
      "\n",
      "    - class:\n",
      "            - class_0\n",
      "            - class_1\n",
      "            - class_2\n",
      "\t\t\n",
      "    :Summary Statistics:\n",
      "    \n",
      "    ============================= ==== ===== ======= =====\n",
      "                                   Min   Max   Mean     SD\n",
      "    ============================= ==== ===== ======= =====\n",
      "    Alcohol:                      11.0  14.8    13.0   0.8\n",
      "    Malic Acid:                   0.74  5.80    2.34  1.12\n",
      "    Ash:                          1.36  3.23    2.36  0.27\n",
      "    Alcalinity of Ash:            10.6  30.0    19.5   3.3\n",
      "    Magnesium:                    70.0 162.0    99.7  14.3\n",
      "    Total Phenols:                0.98  3.88    2.29  0.63\n",
      "    Flavanoids:                   0.34  5.08    2.03  1.00\n",
      "    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\n",
      "    Proanthocyanins:              0.41  3.58    1.59  0.57\n",
      "    Colour Intensity:              1.3  13.0     5.1   2.3\n",
      "    Hue:                          0.48  1.71    0.96  0.23\n",
      "    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\n",
      "    Proline:                       278  1680     746   315\n",
      "    ============================= ==== ===== ======= =====\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML Wine recognition datasets.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
      "\n",
      "The data is the results of a chemical analysis of wines grown in the same\n",
      "region in Italy by three different cultivators. There are thirteen different\n",
      "measurements taken for different constituents found in the three types of\n",
      "wine.\n",
      "\n",
      "Original Owners: \n",
      "\n",
      "Forina, M. et al, PARVUS - \n",
      "An Extendible Package for Data Exploration, Classification and Correlation. \n",
      "Institute of Pharmaceutical and Food Analysis and Technologies,\n",
      "Via Brigata Salerno, 16147 Genoa, Italy.\n",
      "\n",
      "Citation:\n",
      "\n",
      "Lichman, M. (2013). UCI Machine Learning Repository\n",
      "[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\n",
      "School of Information and Computer Science. \n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  (1) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  Comparison of Classifiers in High Dimensional Settings, \n",
      "  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Technometrics). \n",
      "\n",
      "  The data was used with many others for comparing various \n",
      "  classifiers. The classes are separable, though only RDA \n",
      "  has achieved 100% correct classification. \n",
      "  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \n",
      "  (All results using the leave-one-out technique) \n",
      "\n",
      "  (2) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \n",
      "  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Journal of Chemometrics).\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Description:\\n\",df.DESCR, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c91129f",
   "metadata": {},
   "source": [
    "## frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9327c688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame:\n",
      " None \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Frame:\\n\",df.frame, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6aab82",
   "metadata": {},
   "source": [
    "## target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e679dedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target:\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Target:\\n\",df.target, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985e8884",
   "metadata": {},
   "source": [
    "## data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "bb3e8023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data:\n",
      " [[1.423e+01 1.710e+00 2.430e+00 ... 1.040e+00 3.920e+00 1.065e+03]\n",
      " [1.320e+01 1.780e+00 2.140e+00 ... 1.050e+00 3.400e+00 1.050e+03]\n",
      " [1.316e+01 2.360e+00 2.670e+00 ... 1.030e+00 3.170e+00 1.185e+03]\n",
      " ...\n",
      " [1.327e+01 4.280e+00 2.260e+00 ... 5.900e-01 1.560e+00 8.350e+02]\n",
      " [1.317e+01 2.590e+00 2.370e+00 ... 6.000e-01 1.620e+00 8.400e+02]\n",
      " [1.413e+01 4.100e+00 2.740e+00 ... 6.100e-01 1.600e+00 5.600e+02]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Data:\\n\",df.data, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af679e5",
   "metadata": {},
   "source": [
    "## print the label type of the iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "92aceb00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:\n",
      " ['class_0' 'class_1' 'class_2'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Labels:\\n\",df.target_names, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf9e526",
   "metadata": {},
   "source": [
    "# Dividir el conjunto de datos en 70% de entrenamiento y 30% de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "38b81cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.data\n",
    "y = df.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=109)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "659e1ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "bce5ae65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "9118477a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e8366808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a62354",
   "metadata": {},
   "source": [
    "# Crear un clasificador svm con kernel lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ac2f8a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d3b72a",
   "metadata": {},
   "source": [
    "# Entrenar al modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "71ff15db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a8614a",
   "metadata": {},
   "source": [
    "# Predecir la respuesta para el conjunto de datos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "894e8d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c686d98",
   "metadata": {},
   "source": [
    "### print y_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d3663a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred:\n",
      " [0 0 1 2 0 1 0 0 1 0 1 2 2 2 0 1 1 0 0 0 2 1 0 2 0 0 1 2 0 1 2 1 1 0 1 1 0\n",
      " 2 2 0 2 0 0 0 0 2 2 0 1 1 2 0 0 2] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"y_pred:\\n\",y_pred, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e148a764",
   "metadata": {},
   "source": [
    "#### print X_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "3751cb8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test:\n",
      " [[1.330000e+01 1.720000e+00 2.140000e+00 1.700000e+01 9.400000e+01\n",
      "  2.400000e+00 2.190000e+00 2.700000e-01 1.350000e+00 3.950000e+00\n",
      "  1.020000e+00 2.770000e+00 1.285000e+03]\n",
      " [1.293000e+01 3.800000e+00 2.650000e+00 1.860000e+01 1.020000e+02\n",
      "  2.410000e+00 2.410000e+00 2.500000e-01 1.980000e+00 4.500000e+00\n",
      "  1.030000e+00 3.520000e+00 7.700000e+02]\n",
      " [1.221000e+01 1.190000e+00 1.750000e+00 1.680000e+01 1.510000e+02\n",
      "  1.850000e+00 1.280000e+00 1.400000e-01 2.500000e+00 2.850000e+00\n",
      "  1.280000e+00 3.070000e+00 7.180000e+02]\n",
      " [1.253000e+01 5.510000e+00 2.640000e+00 2.500000e+01 9.600000e+01\n",
      "  1.790000e+00 6.000000e-01 6.300000e-01 1.100000e+00 5.000000e+00\n",
      "  8.200000e-01 1.690000e+00 5.150000e+02]\n",
      " [1.421000e+01 4.040000e+00 2.440000e+00 1.890000e+01 1.110000e+02\n",
      "  2.850000e+00 2.650000e+00 3.000000e-01 1.250000e+00 5.240000e+00\n",
      "  8.700000e-01 3.330000e+00 1.080000e+03]\n",
      " [1.311000e+01 1.010000e+00 1.700000e+00 1.500000e+01 7.800000e+01\n",
      "  2.980000e+00 3.180000e+00 2.600000e-01 2.280000e+00 5.300000e+00\n",
      "  1.120000e+00 3.180000e+00 5.020000e+02]\n",
      " [1.285000e+01 1.600000e+00 2.520000e+00 1.780000e+01 9.500000e+01\n",
      "  2.480000e+00 2.370000e+00 2.600000e-01 1.460000e+00 3.930000e+00\n",
      "  1.090000e+00 3.630000e+00 1.015000e+03]\n",
      " [1.299000e+01 1.670000e+00 2.600000e+00 3.000000e+01 1.390000e+02\n",
      "  3.300000e+00 2.890000e+00 2.100000e-01 1.960000e+00 3.350000e+00\n",
      "  1.310000e+00 3.500000e+00 9.850000e+02]\n",
      " [1.216000e+01 1.610000e+00 2.310000e+00 2.280000e+01 9.000000e+01\n",
      "  1.780000e+00 1.690000e+00 4.300000e-01 1.560000e+00 2.450000e+00\n",
      "  1.330000e+00 2.260000e+00 4.950000e+02]\n",
      " [1.374000e+01 1.670000e+00 2.250000e+00 1.640000e+01 1.180000e+02\n",
      "  2.600000e+00 2.900000e+00 2.100000e-01 1.620000e+00 5.850000e+00\n",
      "  9.200000e-01 3.200000e+00 1.060000e+03]\n",
      " [1.264000e+01 1.360000e+00 2.020000e+00 1.680000e+01 1.000000e+02\n",
      "  2.020000e+00 1.410000e+00 5.300000e-01 6.200000e-01 5.750000e+00\n",
      "  9.800000e-01 1.590000e+00 4.500000e+02]\n",
      " [1.229000e+01 1.610000e+00 2.210000e+00 2.040000e+01 1.030000e+02\n",
      "  1.100000e+00 1.020000e+00 3.700000e-01 1.460000e+00 3.050000e+00\n",
      "  9.060000e-01 1.820000e+00 8.700000e+02]\n",
      " [1.371000e+01 5.650000e+00 2.450000e+00 2.050000e+01 9.500000e+01\n",
      "  1.680000e+00 6.100000e-01 5.200000e-01 1.060000e+00 7.700000e+00\n",
      "  6.400000e-01 1.740000e+00 7.400000e+02]\n",
      " [1.369000e+01 3.260000e+00 2.540000e+00 2.000000e+01 1.070000e+02\n",
      "  1.830000e+00 5.600000e-01 5.000000e-01 8.000000e-01 5.880000e+00\n",
      "  9.600000e-01 1.820000e+00 6.800000e+02]\n",
      " [1.320000e+01 1.780000e+00 2.140000e+00 1.120000e+01 1.000000e+02\n",
      "  2.650000e+00 2.760000e+00 2.600000e-01 1.280000e+00 4.380000e+00\n",
      "  1.050000e+00 3.400000e+00 1.050000e+03]\n",
      " [1.176000e+01 2.680000e+00 2.920000e+00 2.000000e+01 1.030000e+02\n",
      "  1.750000e+00 2.030000e+00 6.000000e-01 1.050000e+00 3.800000e+00\n",
      "  1.230000e+00 2.500000e+00 6.070000e+02]\n",
      " [1.204000e+01 4.300000e+00 2.380000e+00 2.200000e+01 8.000000e+01\n",
      "  2.100000e+00 1.750000e+00 4.200000e-01 1.350000e+00 2.600000e+00\n",
      "  7.900000e-01 2.570000e+00 5.800000e+02]\n",
      " [1.364000e+01 3.100000e+00 2.560000e+00 1.520000e+01 1.160000e+02\n",
      "  2.700000e+00 3.030000e+00 1.700000e-01 1.660000e+00 5.100000e+00\n",
      "  9.600000e-01 3.360000e+00 8.450000e+02]\n",
      " [1.387000e+01 1.900000e+00 2.800000e+00 1.940000e+01 1.070000e+02\n",
      "  2.950000e+00 2.970000e+00 3.700000e-01 1.760000e+00 4.500000e+00\n",
      "  1.250000e+00 3.400000e+00 9.150000e+02]\n",
      " [1.334000e+01 9.400000e-01 2.360000e+00 1.700000e+01 1.100000e+02\n",
      "  2.530000e+00 1.300000e+00 5.500000e-01 4.200000e-01 3.170000e+00\n",
      "  1.020000e+00 1.930000e+00 7.500000e+02]\n",
      " [1.340000e+01 4.600000e+00 2.860000e+00 2.500000e+01 1.120000e+02\n",
      "  1.980000e+00 9.600000e-01 2.700000e-01 1.110000e+00 8.500000e+00\n",
      "  6.700000e-01 1.920000e+00 6.300000e+02]\n",
      " [1.237000e+01 9.400000e-01 1.360000e+00 1.060000e+01 8.800000e+01\n",
      "  1.980000e+00 5.700000e-01 2.800000e-01 4.200000e-01 1.950000e+00\n",
      "  1.050000e+00 1.820000e+00 5.200000e+02]\n",
      " [1.483000e+01 1.640000e+00 2.170000e+00 1.400000e+01 9.700000e+01\n",
      "  2.800000e+00 2.980000e+00 2.900000e-01 1.980000e+00 5.200000e+00\n",
      "  1.080000e+00 2.850000e+00 1.045000e+03]\n",
      " [1.281000e+01 2.310000e+00 2.400000e+00 2.400000e+01 9.800000e+01\n",
      "  1.150000e+00 1.090000e+00 2.700000e-01 8.300000e-01 5.700000e+00\n",
      "  6.600000e-01 1.360000e+00 5.600000e+02]\n",
      " [1.372000e+01 1.430000e+00 2.500000e+00 1.670000e+01 1.080000e+02\n",
      "  3.400000e+00 3.670000e+00 1.900000e-01 2.040000e+00 6.800000e+00\n",
      "  8.900000e-01 2.870000e+00 1.285000e+03]\n",
      " [1.348000e+01 1.810000e+00 2.410000e+00 2.050000e+01 1.000000e+02\n",
      "  2.700000e+00 2.980000e+00 2.600000e-01 1.860000e+00 5.100000e+00\n",
      "  1.040000e+00 3.470000e+00 9.200000e+02]\n",
      " [1.270000e+01 3.870000e+00 2.400000e+00 2.300000e+01 1.010000e+02\n",
      "  2.830000e+00 2.550000e+00 4.300000e-01 1.950000e+00 2.570000e+00\n",
      "  1.190000e+00 3.130000e+00 4.630000e+02]\n",
      " [1.279000e+01 2.670000e+00 2.480000e+00 2.200000e+01 1.120000e+02\n",
      "  1.480000e+00 1.360000e+00 2.400000e-01 1.260000e+00 1.080000e+01\n",
      "  4.800000e-01 1.470000e+00 4.800000e+02]\n",
      " [1.438000e+01 1.870000e+00 2.380000e+00 1.200000e+01 1.020000e+02\n",
      "  3.300000e+00 3.640000e+00 2.900000e-01 2.960000e+00 7.500000e+00\n",
      "  1.200000e+00 3.000000e+00 1.547000e+03]\n",
      " [1.242000e+01 2.550000e+00 2.270000e+00 2.200000e+01 9.000000e+01\n",
      "  1.680000e+00 1.840000e+00 6.600000e-01 1.420000e+00 2.700000e+00\n",
      "  8.600000e-01 3.300000e+00 3.150000e+02]\n",
      " [1.277000e+01 2.390000e+00 2.280000e+00 1.950000e+01 8.600000e+01\n",
      "  1.390000e+00 5.100000e-01 4.800000e-01 6.400000e-01 9.899999e+00\n",
      "  5.700000e-01 1.630000e+00 4.700000e+02]\n",
      " [1.208000e+01 1.390000e+00 2.500000e+00 2.250000e+01 8.400000e+01\n",
      "  2.560000e+00 2.290000e+00 4.300000e-01 1.040000e+00 2.900000e+00\n",
      "  9.300000e-01 3.190000e+00 3.850000e+02]\n",
      " [1.182000e+01 1.720000e+00 1.880000e+00 1.950000e+01 8.600000e+01\n",
      "  2.500000e+00 1.640000e+00 3.700000e-01 1.420000e+00 2.060000e+00\n",
      "  9.400000e-01 2.440000e+00 4.150000e+02]\n",
      " [1.305000e+01 1.730000e+00 2.040000e+00 1.240000e+01 9.200000e+01\n",
      "  2.720000e+00 3.270000e+00 1.700000e-01 2.910000e+00 7.200000e+00\n",
      "  1.120000e+00 2.910000e+00 1.150000e+03]\n",
      " [1.184000e+01 8.900000e-01 2.580000e+00 1.800000e+01 9.400000e+01\n",
      "  2.200000e+00 2.210000e+00 2.200000e-01 2.350000e+00 3.050000e+00\n",
      "  7.900000e-01 3.080000e+00 5.200000e+02]\n",
      " [1.181000e+01 2.120000e+00 2.740000e+00 2.150000e+01 1.340000e+02\n",
      "  1.600000e+00 9.900000e-01 1.400000e-01 1.560000e+00 2.500000e+00\n",
      "  9.500000e-01 2.260000e+00 6.250000e+02]\n",
      " [1.373000e+01 1.500000e+00 2.700000e+00 2.250000e+01 1.010000e+02\n",
      "  3.000000e+00 3.250000e+00 2.900000e-01 2.380000e+00 5.700000e+00\n",
      "  1.190000e+00 2.710000e+00 1.285000e+03]\n",
      " [1.258000e+01 1.290000e+00 2.100000e+00 2.000000e+01 1.030000e+02\n",
      "  1.480000e+00 5.800000e-01 5.300000e-01 1.400000e+00 7.600000e+00\n",
      "  5.800000e-01 1.550000e+00 6.400000e+02]\n",
      " [1.308000e+01 3.900000e+00 2.360000e+00 2.150000e+01 1.130000e+02\n",
      "  1.410000e+00 1.390000e+00 3.400000e-01 1.140000e+00 9.400000e+00\n",
      "  5.700000e-01 1.330000e+00 5.500000e+02]\n",
      " [1.356000e+01 1.730000e+00 2.460000e+00 2.050000e+01 1.160000e+02\n",
      "  2.960000e+00 2.780000e+00 2.000000e-01 2.450000e+00 6.250000e+00\n",
      "  9.800000e-01 3.030000e+00 1.120000e+03]\n",
      " [1.317000e+01 5.190000e+00 2.320000e+00 2.200000e+01 9.300000e+01\n",
      "  1.740000e+00 6.300000e-01 6.100000e-01 1.550000e+00 7.900000e+00\n",
      "  6.000000e-01 1.480000e+00 7.250000e+02]\n",
      " [1.324000e+01 3.980000e+00 2.290000e+00 1.750000e+01 1.030000e+02\n",
      "  2.640000e+00 2.630000e+00 3.200000e-01 1.660000e+00 4.360000e+00\n",
      "  8.200000e-01 3.000000e+00 6.800000e+02]\n",
      " [1.305000e+01 1.650000e+00 2.550000e+00 1.800000e+01 9.800000e+01\n",
      "  2.450000e+00 2.430000e+00 2.900000e-01 1.440000e+00 4.250000e+00\n",
      "  1.120000e+00 2.510000e+00 1.105000e+03]\n",
      " [1.419000e+01 1.590000e+00 2.480000e+00 1.650000e+01 1.080000e+02\n",
      "  3.300000e+00 3.930000e+00 3.200000e-01 1.860000e+00 8.700000e+00\n",
      "  1.230000e+00 2.820000e+00 1.680000e+03]\n",
      " [1.406000e+01 1.630000e+00 2.280000e+00 1.600000e+01 1.260000e+02\n",
      "  3.000000e+00 3.170000e+00 2.400000e-01 2.100000e+00 5.650000e+00\n",
      "  1.090000e+00 3.710000e+00 7.800000e+02]\n",
      " [1.293000e+01 2.810000e+00 2.700000e+00 2.100000e+01 9.600000e+01\n",
      "  1.540000e+00 5.000000e-01 5.300000e-01 7.500000e-01 4.600000e+00\n",
      "  7.700000e-01 2.310000e+00 6.000000e+02]\n",
      " [1.349000e+01 3.590000e+00 2.190000e+00 1.950000e+01 8.800000e+01\n",
      "  1.620000e+00 4.800000e-01 5.800000e-01 8.800000e-01 5.700000e+00\n",
      "  8.100000e-01 1.820000e+00 5.800000e+02]\n",
      " [1.339000e+01 1.770000e+00 2.620000e+00 1.610000e+01 9.300000e+01\n",
      "  2.850000e+00 2.940000e+00 3.400000e-01 1.450000e+00 4.800000e+00\n",
      "  9.200000e-01 3.220000e+00 1.195000e+03]\n",
      " [1.179000e+01 2.130000e+00 2.780000e+00 2.850000e+01 9.200000e+01\n",
      "  2.130000e+00 2.240000e+00 5.800000e-01 1.760000e+00 3.000000e+00\n",
      "  9.700000e-01 2.440000e+00 4.660000e+02]\n",
      " [1.156000e+01 2.050000e+00 3.230000e+00 2.850000e+01 1.190000e+02\n",
      "  3.180000e+00 5.080000e+00 4.700000e-01 1.870000e+00 6.000000e+00\n",
      "  9.300000e-01 3.690000e+00 4.650000e+02]\n",
      " [1.340000e+01 3.910000e+00 2.480000e+00 2.300000e+01 1.020000e+02\n",
      "  1.800000e+00 7.500000e-01 4.300000e-01 1.410000e+00 7.300000e+00\n",
      "  7.000000e-01 1.560000e+00 7.500000e+02]\n",
      " [1.247000e+01 1.520000e+00 2.200000e+00 1.900000e+01 1.620000e+02\n",
      "  2.500000e+00 2.270000e+00 3.200000e-01 3.280000e+00 2.600000e+00\n",
      "  1.160000e+00 2.630000e+00 9.370000e+02]\n",
      " [1.422000e+01 1.700000e+00 2.300000e+00 1.630000e+01 1.180000e+02\n",
      "  3.200000e+00 3.000000e+00 2.600000e-01 2.030000e+00 6.380000e+00\n",
      "  9.400000e-01 3.310000e+00 9.700000e+02]\n",
      " [1.286000e+01 1.350000e+00 2.320000e+00 1.800000e+01 1.220000e+02\n",
      "  1.510000e+00 1.250000e+00 2.100000e-01 9.400000e-01 4.100000e+00\n",
      "  7.600000e-01 1.290000e+00 6.300000e+02]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"X_test:\\n\",X_test, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce30718d",
   "metadata": {},
   "source": [
    "### print y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ae08a9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test:\n",
      " [0 0 1 2 0 1 0 1 1 0 1 1 2 2 0 1 1 0 0 1 2 1 0 2 0 0 1 2 0 1 2 1 1 0 1 1 0\n",
      " 2 2 0 2 0 0 0 0 2 2 0 1 1 2 1 0 2] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"y_test:\\n\",y_test, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebb4ef8",
   "metadata": {},
   "source": [
    "# Evaluar el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e26464",
   "metadata": {},
   "source": [
    "#### Precisión del modelo: ¿con qué frecuencia es correcto el clasificador?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c0362ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9259259259259259\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae90a28",
   "metadata": {},
   "source": [
    "#### Precisión del modelo: ¿Qué porcentaje de tuplas positivas están etiquetadas como tales? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d322747d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [137]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecision:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecision_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1757\u001b[0m, in \u001b[0;36mprecision_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1628\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprecision_score\u001b[39m(\n\u001b[0;32m   1629\u001b[0m     y_true,\n\u001b[0;32m   1630\u001b[0m     y_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1636\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1637\u001b[0m ):\n\u001b[0;32m   1638\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute the precision.\u001b[39;00m\n\u001b[0;32m   1639\u001b[0m \n\u001b[0;32m   1640\u001b[0m \u001b[38;5;124;03m    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1755\u001b[0m \u001b[38;5;124;03m    array([0.5, 1. , 1. ])\u001b[39;00m\n\u001b[0;32m   1756\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1757\u001b[0m     p, _, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_recall_fscore_support\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1758\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1759\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1760\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1761\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1762\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1763\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarn_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprecision\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1764\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1765\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1766\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1767\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m p\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1544\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m beta \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1543\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbeta should be >=0 in the F-beta score\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1544\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43m_check_set_wise_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1546\u001b[0m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[0;32m   1547\u001b[0m samplewise \u001b[38;5;241m=\u001b[39m average \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1365\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1363\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1364\u001b[0m             average_options\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1365\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1366\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget is \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m but average=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Please \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1367\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoose another average setting, one of \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (y_type, average_options)\n\u001b[0;32m   1368\u001b[0m         )\n\u001b[0;32m   1369\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pos_label \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1370\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1371\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNote that pos_label (set to \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) is ignored when \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maverage != \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (got \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m). You may use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1375\u001b[0m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[0;32m   1376\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "print(\"Precision:\", metrics.precision_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54d3b3d",
   "metadata": {},
   "source": [
    "#### Recordatorio del modelo: ¿Qué porcentaje de tuplas positivas están etiquetadas como tales? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "77a490e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [138]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecall:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecall_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1901\u001b[0m, in \u001b[0;36mrecall_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1770\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecall_score\u001b[39m(\n\u001b[0;32m   1771\u001b[0m     y_true,\n\u001b[0;32m   1772\u001b[0m     y_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1778\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1779\u001b[0m ):\n\u001b[0;32m   1780\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute the recall.\u001b[39;00m\n\u001b[0;32m   1781\u001b[0m \n\u001b[0;32m   1782\u001b[0m \u001b[38;5;124;03m    The recall is the ratio ``tp / (tp + fn)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1899\u001b[0m \u001b[38;5;124;03m    array([1. , 1. , 0.5])\u001b[39;00m\n\u001b[0;32m   1900\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1901\u001b[0m     _, r, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_recall_fscore_support\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1902\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1903\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1904\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1905\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1906\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1907\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarn_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrecall\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1908\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1909\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1910\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1911\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1544\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m beta \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1543\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbeta should be >=0 in the F-beta score\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1544\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43m_check_set_wise_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1546\u001b[0m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[0;32m   1547\u001b[0m samplewise \u001b[38;5;241m=\u001b[39m average \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1365\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1363\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1364\u001b[0m             average_options\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1365\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1366\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget is \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m but average=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Please \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1367\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoose another average setting, one of \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (y_type, average_options)\n\u001b[0;32m   1368\u001b[0m         )\n\u001b[0;32m   1369\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pos_label \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1370\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1371\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNote that pos_label (set to \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) is ignored when \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maverage != \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (got \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m). You may use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1375\u001b[0m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[0;32m   1376\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "print(\"Recall:\", metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c6e248",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
